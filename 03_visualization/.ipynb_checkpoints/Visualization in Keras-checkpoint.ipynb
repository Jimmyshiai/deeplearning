{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Visualizing Deep-Learning in Keras\n",
    "#### This program was created based on the following links: \n",
    "http://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/\n",
    "\n",
    "####  The target of this coding is:\n",
    "1. Understanding how the text / tensors are transformed in the whole process by what functions.\n",
    "2. Intuitively knowing how RNN / GRU / LSTM / Attention are workings, and comparing the difference among them.\n",
    "3. Trying to make the online / increamental training worked.\n",
    "4. Starting to understand the transferring learning.\n",
    "\n",
    "Since this code will be visualized by tensorboard, it is proposed to start tensorboard in the folder where this code is located in the command windows by the following command:\n",
    "> tensorboard --logdir=logs/\n",
    "\n",
    "The usage of tensorboard can be found in the following link:\n",
    "https://www.analyticsvidhya.com/blog/2017/07/debugging-neural-network-with-tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding,LSTM\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# This code was tested with TensorFlow v1.4\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Load the mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 9,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like apple</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate banana</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence     label\n",
       "0   I like apple  positive\n",
       "1  I hate banana  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(columns=[\"sentence\",\"label\"])\n",
    "df[\"sentence\"]=[\"I like apple\",\"I hate banana\"]\n",
    "df[\"label\"]=[\"positive\",\"negative\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 15,
        "hidden": false,
        "row": 8,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    1\n",
       "positive    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 9,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "#train_size = int(len(df) * .8)\n",
    "train_size = len(df)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "#print (\"Test size: %d\" % (len(df) - train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 13,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Convert the words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "train_narrative = df[\"sentence\"][:train_size]\n",
    "train_product = df[\"label\"][:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Open question: why the max_words is required?\n",
    "max_words = 5\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_narrative) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_narrative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_product)\n",
    "y_train = encoder.transform(train_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 13,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2, 5)\n",
      "y_train shape: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 1.]]\n",
      "[[0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Open questions: why are those parameters used for?\n",
    "batch_size = 2\n",
    "epochs = 1\n",
    "hidden_units=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 18\n",
      "Trainable params: 18\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INPUT-HIDDEN LAYER WEIGHTS:\n",
      "[[ 0.8273283   0.7599194 ]\n",
      " [ 0.07757568  0.19754624]\n",
      " [ 0.8081137  -0.30484623]\n",
      " [ 0.40900648 -0.68801194]\n",
      " [ 0.47900438  0.14262772]]\n",
      "INPUT-HIDDEN LAYER BIASES:\n",
      "[0. 0.]\n",
      "HIDDEN-OUTPUT LAYER WEIGHTS:\n",
      "[[-0.2527665   0.85331285]\n",
      " [-0.89327574 -1.1070108 ]]\n",
      "OUT-HIDDEN LAYER BIASES:\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "#model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Dense(hidden_units, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "summary = model.summary()\n",
    "W_Input_Hidden = model.layers[0].get_weights()[0]\n",
    "B_Input_Hidden= model.layers[0].get_weights()[1]\n",
    "\n",
    "W_Output_Hidden = model.layers[3].get_weights()[0]\n",
    "B_Output_Hidden= model.layers[3].get_weights()[1]\n",
    "\n",
    "print(summary)\n",
    "print('INPUT-HIDDEN LAYER WEIGHTS:')\n",
    "print(W_Input_Hidden)\n",
    "\n",
    "print('INPUT-HIDDEN LAYER BIASES:')\n",
    "print(B_Input_Hidden)\n",
    "\n",
    "print('HIDDEN-OUTPUT LAYER WEIGHTS:')\n",
    "print(W_Output_Hidden)\n",
    "\n",
    "print('OUT-HIDDEN LAYER BIASES:')\n",
    "print(B_Output_Hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Loss function and optimizer\n",
    "A model needs a loss function and an optimizer for training. Since this is a categorical classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), we'll use the categorical_crossentropy loss function.\n",
    "This isn't the only choice for a loss function, you could, for instance, choose mean_squared_error. But, generally, categorical_crossentropy is better for dealing with probabilitiesâ€”it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions.\n",
    "Later, when we are exploring regression problems (say, to predict the price of a house), we will see how to use another loss function called mean squared error.\n",
    "Now, configure the model to use an optimizer and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 16,
        "hidden": false,
        "row": 21,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.0903 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Configure the tensorboard with specifying the log folder and timing.\n",
    "#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=1, write_graph=True, write_images=True)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), write_graph=True, write_images=True)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "INPUT-HIDDEN LAYER WEIGHTS:\n",
      "[[ 0.8273283   0.7599194 ]\n",
      " [ 0.07683155  0.19754624]\n",
      " [ 0.8081137  -0.30484623]\n",
      " [ 0.40900648 -0.68801194]\n",
      " [ 0.47826025  0.14262772]]\n",
      "INPUT-HIDDEN LAYER BIASES:\n",
      "[-0.00074413  0.        ]\n",
      "HIDDEN-OUTPUT LAYER WEIGHTS:\n",
      "[[-0.25202236  0.85256875]\n",
      " [-0.89327574 -1.1070108 ]]\n",
      "OUT-HIDDEN LAYER BIASES:\n",
      "[ 0.00074412 -0.00074412]\n"
     ]
    }
   ],
   "source": [
    "W_Input_Hidden = model.layers[0].get_weights()[0]\n",
    "B_Input_Hidden= model.layers[0].get_weights()[1]\n",
    "\n",
    "W_Output_Hidden = model.layers[3].get_weights()[0]\n",
    "B_Output_Hidden= model.layers[3].get_weights()[1]\n",
    "\n",
    "print(summary)\n",
    "print('INPUT-HIDDEN LAYER WEIGHTS:')\n",
    "print(W_Input_Hidden)\n",
    "\n",
    "print('INPUT-HIDDEN LAYER BIASES:')\n",
    "print(B_Input_Hidden)\n",
    "\n",
    "print('HIDDEN-OUTPUT LAYER WEIGHTS:')\n",
    "print(W_Output_Hidden)\n",
    "\n",
    "print('OUT-HIDDEN LAYER BIASES:')\n",
    "print(B_Output_Hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output the model into the built-in imge in Keras\n",
    "# The image can be opened in the next Markdown block\n",
    "plot_model(model, to_file='./img/model_plot.png', \n",
    "           show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./img/model_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the configuration, weights, gradients of each trainable layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense_1', 'trainable': True, 'batch_input_shape': (None, 5), 'dtype': 'float32', 'units': 2, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[ 0.8273283 ,  0.7599194 ],\n",
      "       [ 0.07683155,  0.19754624],\n",
      "       [ 0.8081137 , -0.30484623],\n",
      "       [ 0.40900648, -0.68801194],\n",
      "       [ 0.47826025,  0.14262772]], dtype=float32), array([-0.00074413,  0.        ], dtype=float32)]\n",
      "{'name': 'activation_1', 'trainable': True, 'activation': 'relu'}\n",
      "[]\n",
      "{'name': 'dropout_1', 'trainable': True, 'rate': 0.5, 'noise_shape': None, 'seed': None}\n",
      "[]\n",
      "{'name': 'dense_2', 'trainable': True, 'units': 2, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "[array([[-0.25202236,  0.85256875],\n",
      "       [-0.89327574, -1.1070108 ]], dtype=float32), array([ 0.00074412, -0.00074412], dtype=float32)]\n",
      "{'name': 'activation_2', 'trainable': True, 'activation': 'softmax'}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Output the configuration and weights of each trainable layer\n",
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    print (g)\n",
    "    print (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain the gradients\n",
    "\n",
    "weights = model.trainable_weights # weight tensors\n",
    "weights = [weight for weight in weights if model.get_layer(weight.name.split(\"/\")[0]).trainable] # filter down weights tensors to only ones which are trainable\n",
    "gradients = model.optimizer.get_gradients(model.total_loss, weights) # gradient tensors\n",
    "\n",
    "#print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_tensors = [model.inputs[0], # input data\n",
    "                 model.sample_weights[0], # how much to weight each sample by\n",
    "                 model.targets[0], # labels\n",
    "                 K.learning_phase(), # train or test mode\n",
    "]\n",
    "\n",
    "get_gradients = K.function(inputs=input_tensors, outputs=gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Variable 'dense_1/kernel:0' shape=(5, 2) dtype=float32_ref>, array([[ 0.        ,  0.        ],\n",
      "       [ 0.24179928, -0.0674738 ],\n",
      "       [-0.10690789,  0.        ],\n",
      "       [-0.10690789,  0.        ],\n",
      "       [ 0.34870717, -0.0674738 ]], dtype=float32)), (<tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32_ref>, array([ 0.24179928, -0.0674738 ], dtype=float32)), (<tf.Variable 'dense_2/kernel:0' shape=(2, 2) dtype=float32_ref>, array([[-0.04983826,  0.04983826],\n",
      "       [-0.10738914,  0.10738914]], dtype=float32)), (<tf.Variable 'dense_2/bias:0' shape=(2,) dtype=float32_ref>, array([-0.21890387,  0.21890387], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nb_sample = 2\n",
    "\n",
    "inputs = [x_train, # X\n",
    "          np.ones(nb_sample), # sample weights\n",
    "          y_train, # y\n",
    "          0 # learning phase in TEST mode\n",
    "]\n",
    "\n",
    "\n",
    "print(list(zip(weights, get_gradients(inputs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> q\n"
     ]
    }
   ],
   "source": [
    "text_labels = encoder.classes_ \n",
    "input_sentence = ''\n",
    "while(1):\n",
    "    try:\n",
    "        # Get input sentence\n",
    "        input_sentence = input('> ')\n",
    "        # Check if it is quit case\n",
    "        if input_sentence == 'q' or input_sentence == 'quit': \n",
    "            break\n",
    "        # Normalize sentence\n",
    "        input_sentence = tokenize.texts_to_matrix([input_sentence])       \n",
    "        pred_output = model.predict(np.array(input_sentence))\n",
    "        pred_prob=model.predict_proba(np.array(input_sentence))\n",
    "        predicted_label = text_labels[np.argmax(pred_output)]\n",
    "        print('Bot:', ' '.join([predicted_label,'Probality:',str(pred_prob[0,np.argmax(pred_output)])]))\n",
    "    except KeyError:\n",
    "        print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
