{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Email Classification based on subject and body\n",
    "This program is to demostrate how to build 3 layers of NN to integrate subject and body's classification into one result. \n",
    "\n",
    "The background is, we need to consider both subject and body to make the email classification, the approach can be:<br> </br>\n",
    "1) Build one NN to predict label of email classification (Subject as input), another NN to predict the same label ( Body as input).<br> </br>\n",
    "2) On top of the above, build one more NN to take their inputs to predict the same label.<br> </br>\n",
    "3) Train the above 3 NNs to gain the optimal weights and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:03:58.158356Z",
     "start_time": "2018-12-26T01:03:58.155390Z"
    },
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:01.485602Z",
     "start_time": "2018-12-26T01:03:59.504307Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import logging\n",
    "import csv        \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding,LSTM,Flatten,GRU\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "# This code was tested with TensorFlow v1.4\n",
    "print(\"You have TensorFlow version\", tf.__version__)\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Load the mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:01.708465Z",
     "start_time": "2018-12-26T01:04:01.505221Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 9,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "source = pd.read_excel('../98_data/mail_timesheet_admin_woissue.xlsx', encoding='latin-1')\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:02.837669Z",
     "start_time": "2018-12-26T01:04:02.823027Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df=source[['subject','mailquestion','Category']]\n",
    "df.columns=['Subject','Emails','Cat']\n",
    "# Remove all rows whose emails or subjects are empty\n",
    "df = df[pd.notnull(df['Emails'])]\n",
    "df=df[pd.notnull(df['Subject'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:06.193076Z",
     "start_time": "2018-12-26T01:04:06.186437Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:07.296259Z",
     "start_time": "2018-12-26T01:04:07.289295Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 15,
        "hidden": false,
        "row": 8,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df['Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:11.143579Z",
     "start_time": "2018-12-26T01:04:10.743470Z"
    }
   },
   "outputs": [],
   "source": [
    "from google_text_classification.explore_data import get_num_words_per_sample,plot_sample_length_distribution\n",
    "\n",
    "print(\"Median words per sample:\",get_num_words_per_sample(df['Emails']))\n",
    "\n",
    "plot_sample_length_distribution(df['Emails'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:12.406426Z",
     "start_time": "2018-12-26T01:04:12.388168Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 9,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test\n",
    "train_narrative,test_narrative,train_product, test_product = train_test_split(df['Emails'], df['Cat'],\n",
    "                                                                              random_state=42, train_size=0.8\n",
    "                                                                              )\n",
    "print (\"Train size: %d\" % train_product.shape[0])\n",
    "print (\"Test size: %d\" % test_product.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 13,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Convert the words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:17.189380Z",
     "start_time": "2018-12-26T01:04:17.168378Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find out the maximum words for the dimension of word vectors\n",
    "def text2word(doc):\n",
    "    \"\"\"\n",
    "    Usage: Convert one text into word list.\n",
    "    Input: doc - string list\n",
    "    Output: documents - string list: all sentences in words list.\n",
    "            text_len - int: maximum numbers of words in one sentense\n",
    "            max_text - strig list: the words list of the sentence with maximum words\n",
    "    \"\"\"\n",
    "    return_docs=[]\n",
    "    text_len=0\n",
    "    max_text=''\n",
    "    #for item in df['Emails']:\n",
    "    for item in doc:\n",
    "        text_words=[word for word in str(item).lower().split()]\n",
    "        return_docs.append(text_words)\n",
    "        if len(text_words)> text_len:\n",
    "            text_len=len(text_words)\n",
    "            max_text=text_words\n",
    "    #max_words = text_len\n",
    "    \n",
    "    return return_docs,text_len,max_text\n",
    "\n",
    "documents,max_words,_=text2word(df['Emails'])\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:18.245339Z",
     "start_time": "2018-12-26T01:04:18.089505Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_narrative) # only fit on train\n",
    "x_train_o = tokenize.texts_to_matrix(train_narrative)\n",
    "x_test_o = tokenize.texts_to_matrix(test_narrative)\n",
    "word_index = tokenize.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:19.084610Z",
     "start_time": "2018-12-26T01:04:19.080224Z"
    },
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_product)\n",
    "y_train_o = encoder.transform(train_product)\n",
    "y_test_o = encoder.transform(test_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:20.343821Z",
     "start_time": "2018-12-26T01:04:20.339553Z"
    },
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "num_classes = np.max(y_train_o) + 1\n",
    "y_train_o = utils.to_categorical(y_train_o, num_classes)\n",
    "y_test_o = utils.to_categorical(y_test_o, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:21.299863Z",
     "start_time": "2018-12-26T01:04:21.295420Z"
    }
   },
   "outputs": [],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:22.293905Z",
     "start_time": "2018-12-26T01:04:22.286750Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_t = LabelEncoder()\n",
    "encoder_t.fit(test_product)\n",
    "print(encoder_t.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:23.153558Z",
     "start_time": "2018-12-26T01:04:23.143336Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 13,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
    "print('x_train shape:', x_train_o.shape)\n",
    "print('x_test shape:', x_test_o.shape)\n",
    "print('y_train shape:', y_train_o.shape)\n",
    "print('y_test shape:', y_test_o.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Model of Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:26.147248Z",
     "start_time": "2018-12-26T01:04:26.144018Z"
    },
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Open questions: why are those parameters used for?\n",
    "batch_size = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:27.072714Z",
     "start_time": "2018-12-26T01:04:26.988301Z"
    },
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Loss function and optimizer\n",
    "A model needs a loss function and an optimizer for training. Since this is a categorical classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), we'll use the categorical_crossentropy loss function.\n",
    "This isn't the only choice for a loss function, you could, for instance, choose mean_squared_error. But, generally, categorical_crossentropy is better for dealing with probabilities—it measures the \"distance\" between probability distributions, or in our case, between the ground-truth distribution and the predictions.\n",
    "Later, when we are exploring regression problems (say, to predict the price of a house), we will see how to use another loss function called mean squared error.\n",
    "Now, configure the model to use an optimizer and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:28.881605Z",
     "start_time": "2018-12-26T01:04:28.815503Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:39.035943Z",
     "start_time": "2018-12-26T01:04:30.959284Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 16,
        "hidden": false,
        "row": 21,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train_o, y_train_o,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:43.785322Z",
     "start_time": "2018-12-26T01:04:43.525624Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_prediction=np.zeros((x_train_o.shape[0],y_train_o.shape[1]))\n",
    "for i in range(x_train_o.shape[0]):\n",
    "    prediction = model.predict(np.array([x_train_o[i]]))\n",
    "    b_prediction[i]=prediction[0]\n",
    "    #s_prediction=np.vstack([s_prediction,prediction[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:44.701626Z",
     "start_time": "2018-12-26T01:04:44.696055Z"
    }
   },
   "outputs": [],
   "source": [
    "b_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:45.745961Z",
     "start_time": "2018-12-26T01:04:45.720031Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 21,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of our trained model\n",
    "score = model.evaluate(x_test_o, y_test_o,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:46.913257Z",
     "start_time": "2018-12-26T01:04:46.833543Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produce the test set for integrated model\n",
    "bt_prediction=np.zeros((x_test_o.shape[0],y_test_o.shape[1]))\n",
    "for i in range(x_test_o.shape[0]):\n",
    "    prediction = model.predict(np.array([x_test_o[i]]))\n",
    "    bt_prediction[i]=prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Create a graph of accuracy and loss over time\n",
    "\n",
    "`model.fit()` returns a `History` object that contains a dictionary with everything that happened during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:50.316637Z",
     "start_time": "2018-12-26T01:04:50.309754Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "There are four entries: one for each monitored metric during training and validation. We can use these to plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:52.372897Z",
     "start_time": "2018-12-26T01:04:52.158392Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 9,
        "hidden": false,
        "row": 25,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:53.534599Z",
     "start_time": "2018-12-26T01:04:53.326029Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 9,
        "hidden": false,
        "row": 27,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
    "Notice the training loss decreases with each epoch and the training accuracy increases with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n",
    "This isn't the case for the validation loss and accuracy—they seem to peak after about twenty epochs. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations specific to the training data that do not generalize to test data.\n",
    "For this particular case, we could prevent overfitting by simply stopping the training after twenty or so epochs. Later, you'll see how to do this automatically with a callback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "#### Scenario 1: Verify 10 records in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:04:56.840392Z",
     "start_time": "2018-12-26T01:04:56.811396Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 52,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Here's how to generate a prediction on individual examples\n",
    "text_labels = encoder.classes_ \n",
    "\n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_test_o[i]]))\n",
    "    print(prediction,np.argmax(prediction))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    print(test_narrative.iloc[i][:50], \"...\")\n",
    "    print('Actual label:' + test_product.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:02.129898Z",
     "start_time": "2018-12-26T01:05:02.123719Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 14,
        "hidden": false,
        "row": 50,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Model of Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:03.996439Z",
     "start_time": "2018-12-26T01:05:03.989138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test for subjects\n",
    "s_train_narrative,s_test_narrative,s_train_product, s_test_product = train_test_split(df['Subject'], df['Cat'],\n",
    "                                                                              random_state=42, train_size=0.8\n",
    "                                                                              )\n",
    "print (\"Train size: %d\" % s_train_product.shape[0])\n",
    "print (\"Test size: %d\" % s_test_product.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:10.156628Z",
     "start_time": "2018-12-26T01:05:10.075551Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects,s_max_words,_=text2word(df['Subject'])\n",
    "s_tokenize = text.Tokenizer(num_words=s_max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:17.922409Z",
     "start_time": "2018-12-26T01:05:17.880746Z"
    }
   },
   "outputs": [],
   "source": [
    "s_tokenize.fit_on_texts(s_train_narrative) # only fit on train\n",
    "s_x_train_o = s_tokenize.texts_to_matrix(s_train_narrative)\n",
    "s_x_test_o = s_tokenize.texts_to_matrix(s_test_narrative)\n",
    "s_word_index = s_tokenize.word_index\n",
    "print('Found %s unique tokens.' % len(s_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:20.303447Z",
     "start_time": "2018-12-26T01:05:20.299218Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "s_encoder = LabelEncoder()\n",
    "s_encoder.fit(s_train_product)\n",
    "s_y_train_o = s_encoder.transform(s_train_product)\n",
    "s_y_test_o = s_encoder.transform(s_test_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:21.563188Z",
     "start_time": "2018-12-26T01:05:21.559091Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "s_num_classes = np.max(s_y_train_o) + 1\n",
    "s_y_train_o = utils.to_categorical(s_y_train_o, s_num_classes)\n",
    "s_y_test_o = utils.to_categorical(s_y_test_o, s_num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:22.531704Z",
     "start_time": "2018-12-26T01:05:22.526981Z"
    }
   },
   "outputs": [],
   "source": [
    "s_encoder_t = LabelEncoder()\n",
    "s_encoder_t.fit(s_test_product)\n",
    "print(s_encoder_t.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:23.590469Z",
     "start_time": "2018-12-26T01:05:23.584520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
    "print('s_x_train shape:', s_x_train_o.shape)\n",
    "print('s_x_test shape:', s_x_test_o.shape)\n",
    "print('s_y_train shape:', s_y_train_o.shape)\n",
    "print('s_y_test shape:', s_y_test_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:24.678380Z",
     "start_time": "2018-12-26T01:05:24.675190Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open questions: why are those parameters used for?\n",
    "batch_size = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:25.608072Z",
     "start_time": "2018-12-26T01:05:25.544798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "s_model = Sequential()\n",
    "s_model.add(Dense(16, input_shape=(s_max_words,)))\n",
    "s_model.add(Activation('relu'))\n",
    "s_model.add(Dropout(0.8))\n",
    "s_model.add(Dense(s_num_classes))\n",
    "s_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:26.574613Z",
     "start_time": "2018-12-26T01:05:26.510418Z"
    }
   },
   "outputs": [],
   "source": [
    "s_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:34.738412Z",
     "start_time": "2018-12-26T01:05:27.476841Z"
    }
   },
   "outputs": [],
   "source": [
    "s_history = s_model.fit(s_x_train_o, s_y_train_o,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:34.905811Z",
     "start_time": "2018-12-26T01:05:34.882587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of our trained model\n",
    "s_score = s_model.evaluate(s_x_test_o, s_y_test_o,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', s_score[0])\n",
    "print('Test accuracy:', s_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:44.028502Z",
     "start_time": "2018-12-26T01:05:43.738430Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produce the traning set for integrated model\n",
    "s_prediction=np.zeros((s_x_train_o.shape[0],s_y_train_o.shape[1]))\n",
    "for i in range(s_x_train_o.shape[0]):\n",
    "    prediction = s_model.predict(np.array([s_x_train_o[i]]))\n",
    "    s_prediction[i]=prediction[0]\n",
    "    #s_prediction=np.vstack([s_prediction,prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:44.892966Z",
     "start_time": "2018-12-26T01:05:44.814996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produce the test set for integrated model\n",
    "st_prediction=np.zeros((s_x_test_o.shape[0],s_y_test_o.shape[1]))\n",
    "for i in range(s_x_test_o.shape[0]):\n",
    "    prediction = s_model.predict(np.array([s_x_test_o[i]]))\n",
    "    st_prediction[i]=prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Model of Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:46.616883Z",
     "start_time": "2018-12-26T01:05:46.614032Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Take the prediction of subject and body as input to predict the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:47.655193Z",
     "start_time": "2018-12-26T01:05:47.650629Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open questions: why are those parameters used for?\n",
    "batch_size = 5\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:48.822337Z",
     "start_time": "2018-12-26T01:05:48.762520Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "i_model = Sequential()\n",
    "i_model.add(Dense(16, input_shape=(s_num_classes+num_classes,)))\n",
    "i_model.add(Activation('relu'))\n",
    "i_model.add(Dropout(0.8))\n",
    "i_model.add(Dense(num_classes))\n",
    "i_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:50.338866Z",
     "start_time": "2018-12-26T01:05:50.290385Z"
    }
   },
   "outputs": [],
   "source": [
    "i_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "i_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:05:52.266596Z",
     "start_time": "2018-12-26T01:05:52.261032Z"
    }
   },
   "outputs": [],
   "source": [
    "i_prediction=np.concatenate((b_prediction,s_prediction),axis=1)\n",
    "i_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:06:00.320982Z",
     "start_time": "2018-12-26T01:05:53.322133Z"
    }
   },
   "outputs": [],
   "source": [
    "i_history = i_model.fit(i_prediction, y_train_o,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:06:02.128807Z",
     "start_time": "2018-12-26T01:06:02.105513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of our trained model\n",
    "it_prediction=np.concatenate((bt_prediction,st_prediction),axis=1)\n",
    "it_prediction.shape\n",
    "\n",
    "i_score = i_model.evaluate(it_prediction, y_test_o,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', i_score[0])\n",
    "print('Test accuracy:', i_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T01:06:04.537571Z",
     "start_time": "2018-12-26T01:06:04.445457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here's how to generate a prediction on individual examples\n",
    "text_labels = encoder.classes_ \n",
    "\n",
    "for i in range(10):\n",
    "    # predict label based on subject:\n",
    "    es_prediction = s_model.predict(np.array([s_x_test_o[i]]))\n",
    "    #print(es_prediction[0],np.argmax(prediction))\n",
    "    predicted_label = text_labels[np.argmax(es_prediction)]\n",
    "    print(\"[Subject]: \",s_test_narrative.iloc[i][:50], \"...\")\n",
    "    print(\"Predicted label: \" + predicted_label)\n",
    "    \n",
    "    prediction = model.predict(np.array([x_test_o[i]]))\n",
    "    #print(prediction[0],np.argmax(prediction))\n",
    "    predicted_label = text_labels[np.argmax(prediction)]\n",
    "    print(\"[Body]: \",test_narrative.iloc[i][:50], \"...\")\n",
    "    print(\"Predicted label: \" + predicted_label)\n",
    "    \n",
    "    ei_prediction=np.concatenate((es_prediction,prediction),axis=1)\n",
    "    f_prediction = i_model.predict(ei_prediction)\n",
    "    #print(ei_prediction[0],np.argmax(f_prediction))\n",
    "    predicted_label = text_labels[np.argmax(f_prediction)]\n",
    "    print(\">> Integrated prediction\")\n",
    "    print(\"-->Predicted label: \" + predicted_label)\n",
    "    print('-->Actual label:' + test_product.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
